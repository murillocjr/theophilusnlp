I"§<p><a href="https://github.com/murillocjr/theophilusnlp">Source Code</a></p>

<p>This is what we have so far:</p>

<ul>
  <li>Data: A whole bible text inside TinyDB documents database entities.</li>
  <li>Code: A function that returns the raw text of a whole chapter on receiving the ChapterID</li>
  <li>NLTK environment up and running.</li>
</ul>

<p>The code used to retrieve this information is inside small python scripts available on the GitHub repo associated with this project. Since the data is stored in a database we can query it any way we want; also the chapter data is in a JSON format that also can give us paragraphs and verses individually</p>

<p>Hereâ€™s where the fun begins; we can start playing with query and code to start gaining insights in the data we have:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python d_d_print_books_chapters.py <span class="s1">' wc -l
1255
</span></code></pre></div></div>

<p>We can see that there are 1255 chapters that we will treat as separate documents, so in the end, we could get what is the main topic(s) in any particular chapter/document.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Previous</th>
      <th style="text-align: left">Home</th>
      <th style="text-align: left">Next</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><a href="A-database-support">Database Support</a></td>
      <td style="text-align: left"><a href="A-Î¸ÎµÏŒÏ†Î¹Î»Î¿Ï‚-Journey">Î¸ÎµÏŒÏ†Î¹Î»Î¿Ï‚ Journey</a></td>
      <td style="text-align: left"><a href="A-tokenizing-all-documents">Tokenizing all Documents</a></td>
    </tr>
  </tbody>
</table>
:ET