---
layout: post
title: Hebrew
date: 2020-09-10
---

Let's see how far can we get using hebrew:

First good sign comes from NLTK, running the command:

```python
>>> nltk.corpus.udhr.fileids()
```

returns as part of it's output:

```
'Hebrew_Ivrit-Hebrew', 'Hebrew_Ivrit-UTF8'
```

But sadly, the API chosen at the beginning does not provide a bible in Hebrew. 

For a site that provides so wide a variety of bible versions in several languages, there must be a very good set of reasons as for why Hebrew is not present; I can only blame myself for not checking that while picking a source.

With the purpose of finding a way to make the basic analysis in Hebrew, here's some interesting findings:

*   [https://github.com/openscriptures/morphhb](https://github.com/openscriptures/morphhb)

Other API produces the following:

[](https://getbible.net/json?passage=GEN1:1&version=wlc)

```json
({"book":[{"book_ref":"Ge","book_name":"Genesis","book_nr":"1","chapter_nr":"1","chapter":{"1":{"verse_nr":"1","verse":"\u05d1\u05bc\u05b0\u05e8\u05b5\u05d0\u05e9\u05c1\u05b4\u05d9\u05ea \u05d1\u05bc\u05b8\u05e8\u05b8\u05d0 \u05d0\u05b1\u05dc\u05b9\u05d4\u05b4\u05d9\u05dd \u05d0\u05b5\u05ea \u05d4\u05b7\u05e9\u05c1\u05bc\u05b8\u05de\u05b7\u05d9\u05b4\u05dd \u05d5\u05b0\u05d0\u05b5\u05ea \u05d4\u05b8\u05d0\u05b8\u05e8\u05b6\u05e5\u05c3\r\n"}}}],"direction":"RTL","type":"verse","version":"wlc"});
```

Where "\u05d1" is unicode for the Hebrew letter "Bet" , so it would be better to first see whether NLTK can process the text in this format.

Bad news, there's no hebrew tokenizer in my nltk installation :

```
tokenizers/punkt/czech.pickle
tokenizers/punkt/danish.pickle
tokenizers/punkt/dutch.pickle
tokenizers/punkt/english.pickle
tokenizers/punkt/estonian.pickle
tokenizers/punkt/finnish.pickle
tokenizers/punkt/french.pickle
tokenizers/punkt/german.pickle
tokenizers/punkt/greek.pickle
tokenizers/punkt/italian.pickle
tokenizers/punkt/norwegian.pickle
tokenizers/punkt/polish.pickle
tokenizers/punkt/portuguese.pickle
tokenizers/punkt/russian.pickle
tokenizers/punkt/slovene.pickle
tokenizers/punkt/spanish.pickle
tokenizers/punkt/swedish.pickle
tokenizers/punkt/turkish.pickle
```

This seems like an alternative : [https://github.com/YontiLevin/Hebrew-Tokenizer](https://github.com/YontiLevin/Hebrew-Tokenizer)

```bash
pip install hebrew_tokenizer
```

Which sample code works perfectly (), now lets see how it fares with unicode text:

No dice, it doesn't work with the unicode sample.

Testing another tokenizer: https://www.cs.bgu.ac.il/~yoavg/software/hebtokenizer/
Returns an error

Let's keep looking...

| Previous        | Home          | Next |
|:-------------|:------------------|:------|
| [One Result, Several Questions](A-one-result-several-questions) | [θεόφιλος Journey](A-θεόφιλος-Journey) |  |
